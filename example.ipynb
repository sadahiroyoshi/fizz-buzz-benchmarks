{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fizz Buzz Benchmark Example\n",
    "The explanation how to calc benchmark. (created by @sadahiroyoshi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "import libs & load config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tool.language as language\n",
    "import tool.benchmark as benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all languages in conf/languages.csv.\n",
    "langs = language.load_languages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Your Device Info\n",
    "check your environment before execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print OS info of your device.\n",
    "print( \"platform.system()={}\".format( platform.system() ))\n",
    "print( \"platform.version()={}\".format( platform.version() ))\n",
    "print( \"platform.release()={}\".format( platform.release() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all versions of each langs on your device.\n",
    "for _lang in langs:\n",
    "    language.print_version(_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Method\n",
    "\n",
    "run the method which is wanted to calculate a benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all benchmarks of 'println'\n",
    "method = 'println'\n",
    "n = 100_000\n",
    "r = 10\n",
    "\n",
    "results_by_langs = {}\n",
    "_debug = True\n",
    "for _lang in langs:\n",
    "    # if `debug=True`, you can check actual cmd line in `benchmark.run`\n",
    "    results_by_langs[_lang] = benchmark.run(method, _lang, n, r, debug=_debug)\n",
    "    _debug = False # `debug=True` only at first exec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`benchmark.run` is internally running method of each langs via CLI. The overhead time when staring CLI, may much effects execution time of this method.\n",
    "\n",
    "So after `benchmark.run`, also run the method 'nothing'. this method is 'do nothing' or empty script file of each langs.\n",
    "\n",
    "You will get real execution time by substracting the 'nothing' time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also run scripts 'nothing' (to measure execution time of lang cmd itself)\n",
    "results_by_langs_nothing = {}\n",
    "for _lang in langs:\n",
    "    results_by_langs_nothing[_lang] = benchmark.run('nothing', _lang, n, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate avg of the method & 'nothing'.\n",
    "_avgs = [\n",
    "    sum(results_by_langs[_lang]) / r for _lang in langs\n",
    "]\n",
    "_avgs_nothing = [\n",
    "    sum(results_by_langs_nothing[_lang]) / r for _lang in langs\n",
    "]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    method: _avgs,\n",
    "    'nothing': _avgs_nothing,\n",
    "}, index=langs)\n",
    "df.index.name = 'language'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substracting the 'nothing' time.\n",
    "df['real'] = df[method] - df['nothing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Plot\n",
    "finally, plot these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[method].plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nothing'].plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['real'].plot.barh()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3bb9a330ca8deb56f2ea771eb176a8043d9447eea49f8a3032bdb2a4cfc4ae1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('3.9.7': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
